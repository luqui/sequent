Introduction
------------

This is a programming language designed around the principle that you construct
programs as in Coq's proof mode.

You manipulate both knowledge and variables.  But knowledge manipultion is soft;
you can claim things without proof, assuming you document them.

The code itself is not made to be especially readable.  In fact, the code itself
should almost be absent, like the strokes of an artist, leaving only the
result to represent what the code did.

Signatures play the role of functions in this language. A signature specifies
inputs and outputs, including names and knowledge.

The following three propositions form the definition of Divides.  When asked
for a proof, they will be "proved by definition"; i.e.  moved into the
assumptions when `Divides` is quantified over. (We will talk about numerals
and the `*` symbol later).

    x :nat   -> [1 Divides x]

    x :nat   -> [x Divides 0]

    x y :nat -> [x Divides x*y]

We then define a division with remainder theorem:

    x y :nat -> q r :nat [x = q*y + r] [r < y]

This theorem has outputs (`q` and `r`) which must be computed, so you cannot
simply prove by definition.  You can give expressions for `q` and `r`, however,
and then explain the two returned properties in documentation. I don't know how
yet.

Finally, a `gcd` theorem.  This also returns a witness so it needs a
computation and cannot simply be explained.  However, with what we have built
up, we can compute it without any appeal to an underlying language.

    x y :nat
    ->
    gcd :nat
    [gcd Divides x] [gcd Divides y] 
    ( [d' Divides x] [d' Divides y] -> [d' Divides gcd] )

The witness from applying this theorem can be referred to as `gcd(x,y)`. It
introduces obligations for `x:nat` and `y:nat`, and produces the knowledge
`[gcd(x,y) Divides x]`, etc.

Similarly, the division algorithm can be referred to as `q(x,y)` and `r(x,y)`,
if left defined as above.  When one is applied, the suitably skolemized other
is introduced into the context with it.

Signature Syntax
----------------

A *clause* of a signature is a set of terms, which are variables and
propositions.  The terms are separated by spaces.  A term may be:

* A proposition, which is surrounded in square brackets.  Propositions have
    a free-form syntax, in which the name of the proposition can go between
    its arguments.  For example `[x divides y]` is an example usage or definition
    of the proposition `[_ divides _]`.  What count as variables and what count
    as structure depends on the surrounding quantification.  Parentheses occurring
    in the syntax of a proposition ensure that that position is interpreted
    as an expression. 
* A variable clause, which is a list of variables (as barewords) followed by a
    list of types (each introduced with a colon).  A type is shorthand for a
    proposition: `x :nat` is shorthand for `[nat x]`. The spaces are interpreted
    as part of the type until the next colon or opening bracket, so: 
    `x y : list nat : sorted` is short for the propositions `[list nat x]`,
    `[sorted x]`, `[list nat y]`, `[sorted y]`.

A signature is:

* A clause
* An implication: `P -> Q`, where `P` and `Q` are clauses.

Implication is *non*-associative, you have to insert parentheses to nest
them.  Parentheses should be minimal, because of the conjunctive properties
of clauses.

We can now see how the `gcd` definition might be interpreted:

    x y :int [x > 0] [y > 0]
    -> 
    gcd :int [gcd > 0] [gcd divides x] [gcd divides y]

However, the quantifiers are still unclear.

Quantification
--------------

Signatures are formulas in a logical calculus (it is unclear which one exactly,
and it is rather unimportant because consistency is not necessary).  As such,
the variables in theorems are quantified by universal and existential
quantifiers.  These quantifiers and their destructors are the basis of data
manipulation in sequent.

Every variable in a variable clause is quantified.  The quantification depends
on the position of the variable clause.

* If it occurs to the immediate left of an implication clause, then the
    quantification is universal.  `x y : nat -> ...` means 
    `forall x, forall y, [nat x] [nat y], ...`.
* If not, then the quantification is existential (which, as we will see later,
    introduces a Skolem function). `x : nat -> y : nat` means 
    `forall x, [nat x] -> exists y, [nat y]`.

Skolem Functions
----------------

Every existential quantifier introduces a Skolem function into every appropriate
scope. An appropriate scope is one in which the existential appears in a strictly
positive position (i.e. only to the right of arrows).  So:

    x y :nat -> gcd :nat

Introduces a `gcd` Skolem function in the entire scope of the theorem.  Consider
this generalized version:

    (x y :nat -> q r [x = q*y + r]) 
    x y :nat
    ->
    gcd :nat

Like the last example, `gcd` appears in a strictly positive position for the
scope of the theorem.  However, `q` and `r` appear in a strictly positive
position for the scope of the *proof* (in which `x y :nat -> q r [...]` is used
as an assumption), so the proof may use the `q(x,y)` and `r(x,y)` Skolem
functions.

The parameters of the skolem function depend on the unshared assumptions between
the user of the function and the occurrence of the existential.  Usage of the
function, similarly, instantiates any unshared hypotheses.  Including hypotheses
in the environment reduces the parameters of the Skolem function.

Environment
-----------

Now, there is the pressing question: what do proofs look like? The answer, as I
hinted in the introduction, is nothing.  Proofs are created in an interactive
environment and are immutable and (in principle) unviewable forever.

The environment provides:

* A way to state signatures/theorems that need impliementation/proof.
* A "tactic language" (though not necessarily text-based) to produce
    implementations/proofs.
* A way to introduce and discharge hypotheses and goals.
* A search engine for previously defined signatures

The environment has the ability to edit anything about the context.  If you are
editing a proof, you may introduce a hypotheses into the scope of the theorem
(hence modifying its statement), or into an outer, more global scope (if you
forgot something about the structures you are using).  You may use the tactic
language even when you are not editing a proof, and this modifies the shared
context (eg. it can introduce hypotheses for all further proofs in this
context).

You may discharge goals by either proving them (matching them up with a
hypothesis) or by *documenting* them: admitting them and providing an english
explanation about why this is true.  This documentation goes into the detail
view of theorems, so we can see what non-formal assumptions have been made.

The search engine is whatever I can make of it; it's a complex goal.  But it
ought to be as powerful as possible: you can give it matching criteria for
theorems, e.g. you could query a la Hoogle:

    x y : nat -> z : nat

This will search for theorems that require at least two `nat`s as hypotheses and
give at least a `nat` as a result.  This is not checking for subtypes, but
rather for a sense of matching: often we know what kind of information we will
need to compute something, but we may not realize how much. It is not common
that we don't realize that we *don't* need some information (though a looser
search mode could be provided).  This is long-term stuff so I will leave it for
now.

Object Language
---------------

Sequent is defined *abstractly* in terms of an object language.  For example, a
sequent session may generate a javascript function from each skolem function.
The object language only needs to support basic lambda calculus facilities, the
system will do the stitching given the object language's syntax for lambda and
apply (and various other things, surely).

Even when a goal is discharged by documentation, if the goal required a witness
then a witness must be generated.  This is done in the object language since it
apparently could not be done in sequent.  The witness is simply an expression in
the object language in terms of the hypotheses (which have been reified by some
object language-dependent rule).

Implementing a witness in an object language entangles that implementation to
that language.  Like everything, it is abstracted over, so the parts of the
implementation that do not depend on the object language can be shared between
different object languages.

Abstraction and Tags
--------------------

The full form of signatures are completely quantified, closed terms.  There are
no references to globals.  For some definitions, this quantification context
could be quite large.  That's OK, since to use them you should important an
entire vocabulary into your context.  This will discharge most of the hypotheses
and make the theorem more manageable.

Even if you have imported necessary vocabulary, it is always possible to import
a previously-defined signature more abstractly.  The exact mechanism depends on
the environment, but it essentially alpha renaming: a refusal to expand the
hypotheses of a signature so you can do it manually.
